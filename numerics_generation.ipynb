{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import os \n",
    "import shutil\n",
    "\n",
    "import contactProbability_generator_with_stiffness_new as cmgsp\n",
    "from contactProbability_generator_with_stiffness_new import ChainLayout\n",
    "\n",
    "from mirnylib.numutils import zoomArray\n",
    "import sys\n",
    "sys.setrecursionlimit(4000)\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.pyplot as plt\n",
    "from mirnylib.numutils import iterativeCorrection\n",
    "from itertools import product\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import matplotlib.colors as clr \n",
    "\n",
    "import timeit\n",
    "from scipy.sparse import coo_matrix\n",
    "from mirnylib.numutils import logbins\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "\n",
    "## Distributions that will be used\n",
    "from numpy.random import exponential \n",
    "\n",
    "## simulation parameters\n",
    "chainLen = 10000 # 1 kb monomers\n",
    "monToBP = 2000 \n",
    "\n",
    "def generate_chain(L_tot,loopargs,gapargs):\n",
    "    chain  = []\n",
    "    c_count = 0\n",
    "    \n",
    "    while c_count < L_tot:\n",
    "        # generate loop distributions\n",
    "        keys = loopargs.keys()\n",
    "        if 'exponential' in keys:\n",
    "            lavg = loopargs['exponential']['avg']\n",
    "            lsize = int(exponential(lavg)) # cast to integer\n",
    "            if lsize < 1:\n",
    "                lsize = 1\n",
    "            if c_count + lsize < L_tot:\n",
    "                chain.append((c_count,c_count+lsize))\n",
    "            c_count += lsize\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"loopargs does not have proper arguments\")\n",
    "\n",
    "        # generate gap distribution\n",
    "        keys = gapargs.keys()\n",
    "        if 'exponential' in keys:\n",
    "            gavg = gapargs['exponential']['avg']\n",
    "            gsize = int(exponential(gavg)) # cast to integer\n",
    "            if gsize < 1: \n",
    "                gsize = 1\n",
    "            c_count += gsize\n",
    "        else:\n",
    "            raise ValueError(\"loopargs does not have proper arguments\")\n",
    "    \n",
    "    return chain\n",
    "\n",
    "\n",
    "## fast sampling \n",
    "\n",
    "def doOneChain(L_tot,loopargs,gapargs,nsamples=60,nreps=1000,H=1/2,lp=1,circular=False):\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    P = []\n",
    "    C = []\n",
    "    \n",
    "    for ic in range(nreps):\n",
    "        # generate chain using loop and gap statistics\n",
    "        smcs = generate_chain(L_tot,loopargs,gapargs)\n",
    "        cl = None\n",
    "        try:\n",
    "            if len(smcs)==0:\n",
    "                smcs = [(0,1)]\n",
    "            cl = ChainLayout(smcs,L_tot)\n",
    "        except:\n",
    "            print(\"Pseudoknot formed count:{}\".format(ic))\n",
    "            print(cl)\n",
    "            assert(1==0)\n",
    "            cl = None\n",
    "        if cl is None:\n",
    "            continue\n",
    "\n",
    "        # subsample from distribution \n",
    "        vals = sorted(np.random.choice(L_tot,nsamples, replace=False))\n",
    "        for ix in range(len(vals)):\n",
    "            for iy in range(ix,len(vals)):\n",
    "                x = vals[ix]\n",
    "                y = vals[iy]\n",
    "                deff = cl.get_dist(x,y,H=H,lp=lp,circular=circular)\n",
    "                if deff == 0:\n",
    "                    pc = 1\n",
    "                else:\n",
    "                    pc = 1/np.sqrt(deff)**3\n",
    "                if not np.isnan(pc):\n",
    "                    X.append(x)\n",
    "                    Y.append(y) # x\n",
    "                    P.append(pc) # probability\n",
    "                    C.append(1) # counts\n",
    "\n",
    "    Z = coo_matrix((P,(X,Y)),shape=(L_tot,L_tot))\n",
    "    Zcount = coo_matrix((C,(X,Y)),shape=(L_tot,L_tot))\n",
    "\n",
    "    return Z,Zcount, (P,X,Y)\n",
    "\n",
    "\n",
    "def get_deriv(res, lbins, filter_width):\n",
    "    \n",
    "    \n",
    "    lbins = np.array(lbins)\n",
    "    \n",
    "    ## combine coo matrices\n",
    "    dS = np.concatenate([Z[0].col-Z[0].row for Z in res])\n",
    "    Zdata = np.concatenate([Z[0].data for Z in res])\n",
    "    Zcountdata = np.concatenate([Z[1].data for Z in res])\n",
    "\n",
    "    # do log binning of data\n",
    "    rebinned_dS = np.digitize(dS,lbins,right=True) \n",
    "    freq = np.bincount(rebinned_dS,Zdata)\n",
    "    count_freq = np.bincount(rebinned_dS,Zcountdata)\n",
    "    Pc_s = freq/count_freq\n",
    "    Pc_s = Pc_s[1:]\n",
    "    \n",
    "    bins = [(lbins[i], lbins[i + 1]) for i in range(len(lbins) - 1)]\n",
    "    mids = [np.sqrt(i[0] * (i[1] - 1)) for i in bins]\n",
    "    \n",
    "    dlogP = np.diff(np.log(Pc_s))\n",
    "    dlogS = np.diff(np.log(mids))\n",
    "    \n",
    "    H = dlogP/dlogS\n",
    "    return np.array(mids),gaussian_filter1d(H,filter_width)\n",
    "\n",
    "def get_pc(res, lbins, filter_width):\n",
    "    \n",
    "    lbins = np.array(lbins)\n",
    "\n",
    "    ## combine coo matrices\n",
    "    dS = np.concatenate([Z[0].col-Z[0].row for Z in res])\n",
    "    Zdata = np.concatenate([Z[0].data for Z in res])\n",
    "    Zcountdata = np.concatenate([Z[1].data for Z in res])\n",
    "\n",
    "    # do log binning of data\n",
    "    rebinned_dS = np.digitize(dS,lbins,right=True) \n",
    "    freq = np.bincount(rebinned_dS,Zdata)\n",
    "    count_freq = np.bincount(rebinned_dS,Zcountdata)\n",
    "    Pc_s = freq/count_freq\n",
    "    Pc_s = Pc_s[1:]\n",
    "    \n",
    "    bins = [(lbins[i], lbins[i + 1]) for i in range(len(lbins) - 1)]\n",
    "    mids = [np.sqrt(i[0] * (i[1] - 1)) for i in bins]\n",
    "\n",
    "    return np.array(mids),Pc_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain length\n",
    "chainLen = 10000\n",
    "\n",
    "# binning\n",
    "from mirnylib.numutils import logbinsnew\n",
    "bins = logbinsnew(1, chainLen, 1.3)\n",
    "\n",
    "# parameters of the model\n",
    "H = 1/3\n",
    "lavg = 100\n",
    "gavg = 50\n",
    "lp = 2\n",
    "\n",
    "# loops and gaps distribution\n",
    "loopargs= {'exponential': {'avg': lavg }}\n",
    "gapargs = {'exponential': {'avg': gavg }}\n",
    "\n",
    "# sampling statistics\n",
    "nsamples=100\n",
    "nreps=5000\n",
    "num_cores=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running\n",
    "with Pool(num_cores) as mypool:\n",
    "    res = mypool.starmap(doOneChain, list(product([chainLen], [loopargs]*num_cores, [gapargs],[nsamples],[nreps],[H],[lp],[False]  )))\n",
    "mypool.close()\n",
    "\n",
    "# compute P(s) and slopes from generated dataframes\n",
    "mids, pc = get_pc(res, bins, filter_width=1)\n",
    "mids, Hder = get_deriv(res, bins, filter_width=1)\n",
    "\n",
    "# free up space\n",
    "del res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "font = {'family' : 'Arial',\n",
    "    'weight' : 'medium',\n",
    "    'size'   : 14,\n",
    "    'style'  : 'normal'}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "\n",
    "color_idx = np.linspace(0, 1, 6)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 7)) \n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[3, 1]) \n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax1 = plt.subplot(gs[1])\n",
    "\n",
    "ax0.plot(mids, pc, color='k', linewidth=2)\n",
    "\n",
    "ax0.set_xscale('log')\n",
    "ax0.set_yscale('log')\n",
    "\n",
    "ax1.plot(mids[1:], Hder, color='k', linewidth=2)\n",
    "\n",
    "ax1.set_xscale('log')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
